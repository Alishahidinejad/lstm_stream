{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LSTMs to predict river flow\n",
    "Welcome. This notebook will demonstrate using a LSTM built with Keras to predict the flow of a stream. Let's first take a look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfallh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.63</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.66</td>\n",
       "      <td>44.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.70</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.78</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.82</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.86</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.90</td>\n",
       "      <td>41.9</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.94</td>\n",
       "      <td>41.9</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.97</td>\n",
       "      <td>42.7</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.03</td>\n",
       "      <td>43.8</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.04</td>\n",
       "      <td>44.9</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.05</td>\n",
       "      <td>46.4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.06</td>\n",
       "      <td>48.4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.05</td>\n",
       "      <td>51.8</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.04</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.03</td>\n",
       "      <td>52.6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.03</td>\n",
       "      <td>52.7</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.01</td>\n",
       "      <td>52.8</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.98</td>\n",
       "      <td>52.7</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.97</td>\n",
       "      <td>51.7</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.95</td>\n",
       "      <td>50.9</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.94</td>\n",
       "      <td>50.1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.92</td>\n",
       "      <td>49.7</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.90</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.88</td>\n",
       "      <td>49.1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.85</td>\n",
       "      <td>48.8</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.83</td>\n",
       "      <td>48.6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.81</td>\n",
       "      <td>48.4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.79</td>\n",
       "      <td>48.4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.77</td>\n",
       "      <td>50.4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>5.42</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>5.37</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>5.35</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>5.32</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>5.30</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>5.27</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>5.21</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512</th>\n",
       "      <td>5.18</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513</th>\n",
       "      <td>5.16</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3514</th>\n",
       "      <td>5.13</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>5.10</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>5.05</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>5.03</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>5.01</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>4.98</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>4.95</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>4.89</td>\n",
       "      <td>26.9</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>4.86</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>4.82</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>4.79</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>4.76</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>4.73</td>\n",
       "      <td>29.8</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>4.71</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>4.70</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>4.70</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>4.69</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>4.69</td>\n",
       "      <td>24.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>4.68</td>\n",
       "      <td>24.1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>4.67</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>4.65</td>\n",
       "      <td>26.9</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3535 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      height  temp  rainfallh\n",
       "0       4.63  45.0       0.00\n",
       "1       4.66  44.5       0.00\n",
       "2       4.70  44.2       0.00\n",
       "3       4.78  44.0       0.00\n",
       "4       4.82  43.5       0.00\n",
       "5       4.86  42.8       0.00\n",
       "6       4.90  41.9       0.00\n",
       "7       4.94  41.9       0.00\n",
       "8       4.97  42.7       0.00\n",
       "9       5.03  43.8       0.00\n",
       "10      5.04  44.9       0.00\n",
       "11      5.05  46.4       0.00\n",
       "12      5.06  48.4       0.00\n",
       "13      5.05  51.8       0.00\n",
       "14      5.04  51.0       0.00\n",
       "15      5.03  52.6       0.00\n",
       "16      5.03  52.7       0.01\n",
       "17      5.01  52.8       0.00\n",
       "18      4.98  52.7       0.00\n",
       "19      4.97  51.7       0.00\n",
       "20      4.95  50.9       0.00\n",
       "21      4.94  50.1       0.00\n",
       "22      4.92  49.7       0.00\n",
       "23      4.90  49.3       0.00\n",
       "24      4.88  49.1       0.00\n",
       "25      4.85  48.8       0.00\n",
       "26      4.83  48.6       0.00\n",
       "27      4.81  48.4       0.00\n",
       "28      4.79  48.4       0.00\n",
       "29      4.77  50.4       0.00\n",
       "...      ...   ...        ...\n",
       "3505    5.42  30.0       0.00\n",
       "3506    5.37  27.6       0.00\n",
       "3507    5.35  24.5       0.00\n",
       "3508    5.32  22.9       0.00\n",
       "3509    5.30  21.6       0.00\n",
       "3510    5.27  21.5       0.00\n",
       "3511    5.21  19.2       0.00\n",
       "3512    5.18  20.9       0.00\n",
       "3513    5.16  18.4       0.00\n",
       "3514    5.13  17.1       0.00\n",
       "3515    5.10  17.2       0.00\n",
       "3516    5.05  15.4       0.00\n",
       "3517    5.03  14.8       0.00\n",
       "3518    5.01  14.6       0.00\n",
       "3519    4.98  16.2       0.00\n",
       "3520    4.95  21.5       0.00\n",
       "3521    4.89  26.9       0.00\n",
       "3522    4.86  29.9       0.00\n",
       "3523    4.82  32.8       0.00\n",
       "3524    4.79  34.2       0.00\n",
       "3525    4.76  34.2       0.00\n",
       "3526    4.73  29.8       0.00\n",
       "3527    4.71  27.5       0.00\n",
       "3528    4.70  26.2       0.00\n",
       "3529    4.70  25.1       0.00\n",
       "3530    4.69  25.0       0.00\n",
       "3531    4.69  24.2       0.00\n",
       "3532    4.68  24.1       0.00\n",
       "3533    4.67  25.6       0.00\n",
       "3534    4.65  26.9       0.00\n",
       "\n",
       "[3535 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# Get some time series data\n",
    "df = pd.read_csv(\"height2.csv\")\n",
    "df = df[['height', 'temp', 'rainfallh']]\n",
    "df.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3535\n",
      "(3535,)\n"
     ]
    }
   ],
   "source": [
    "# Our core functions will be here\n",
    "\n",
    "# This function reas the CSV and gets the necessary rows\n",
    "def read_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['height', 'temp', 'rainfallh']]\n",
    "    df.dropna()\n",
    "    #X_test, actual = get_split(df)\n",
    "    # Save it as a list\n",
    "    return format_data(df)\n",
    "\n",
    "\n",
    "def format_data(df):\n",
    "    # According to the advice in the post located at \n",
    "    # http://stackoverflow.com/questions/39674713/neural-network-lstm-keras\n",
    "    height2, predictors = get_split(df)\n",
    "    df['single_input_vector'] = predictors.apply(tuple, axis=1).apply(list)\n",
    "    # Double-encapsulate list so that you can sum it in the next step and keep time steps as separate elements\n",
    "    df['single_input_vector'] = df.single_input_vector.apply(lambda x: [list(x)])\n",
    "    df['cumulative_input_vectors'] = df.single_input_vector.cumsum()\n",
    "    max_sequence_length = df.cumulative_input_vectors.apply(len).max()\n",
    "    padded_sequences = pad_sequences(df.cumulative_input_vectors.tolist(), max_sequence_length).tolist()\n",
    "    df['padded_input_vectors'] = pd.Series(padded_sequences).apply(np.asarray)\n",
    "    print(len(df))\n",
    "    X_train_init = np.asarray(df.padded_input_vectors)\n",
    "    print(X_train_init.shape)\n",
    "    s = np.hstack(X_train_init)\n",
    "    fin = s.reshape(len(df),len(df),2)\n",
    "    y_train = np.hstack(np.asarray(height2))\n",
    "    return fin, y_train\n",
    "\n",
    "\n",
    "def get_split(dataset):\n",
    "    #print(dataset.drop('height',1))\n",
    "    return dataset['height'], dataset.drop('height',1)\n",
    "\n",
    "X_train, y_train = read_csv('height.csv')\n",
    "#print(predictors[rainfallh].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3535, 3535, 2]\n"
     ]
    }
   ],
   "source": [
    "#df['output_vector'].head()\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import callbacks\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "def build_model(layers):\n",
    "    print(layers)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_shape=(None,2),\n",
    "        units=20,\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        100,\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "        1))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    \n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    #print(\"> Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "\n",
    "callback =callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "model = build_model([2, 3535,3535,2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3535, 3535, 2]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, None, 20)          1840      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, None, 20)          0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 100)               48400     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 50,341.0\n",
      "Trainable params: 50,341.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[ 4.63  4.66  4.7  ...,  4.68  4.67  4.65]\n",
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model.summary())\n",
    "print(y_train)\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3535, 3535, 2]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, None, 20)          1840      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, None, 20)          0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               48400     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 50,341.0\n",
      "Trainable params: 50,341.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3358 samples, validate on 177 samples\n",
      "Epoch 1/2\n",
      "3358/3358 [==============================] - 1221s - loss: 4.7795 - val_loss: 2.0513\n",
      "Epoch 2/2\n",
      "3358/3358 [==============================] - 1356s - loss: 0.9069 - val_loss: 1.5681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12223c940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load_data(\"height.csv\", 20 ,True)\n",
    "model = build_model([2, 3535, 3535, 2])\n",
    "print(model.summary())\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    epochs=2,\n",
    "    validation_split=0.05, \n",
    "    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction function gotten from tutorial. Located at following url\n",
    "#http://www.jakob-aungiers.com/articles/a/LSTM-Neural-Network-for-Time-Series-Prediction\n",
    "from numpy import newaxis\n",
    "def predict_sequences_multiple(model, data, window_size, prediction_len):\n",
    "    #Predict sequence of 50 steps before shifting prediction run forward by 50 steps\n",
    "    prediction_seqs = []\n",
    "    for i in range(int(len(data)/prediction_len)):\n",
    "        curr_frame = data[i*prediction_len]\n",
    "        predicted = []\n",
    "        for j in range(prediction_len):\n",
    "            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "            curr_frame = curr_frame[1:]\n",
    "            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "    return prediction_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x119c5a208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "from keras.models import load_model\n",
    "#model.save('my_model24.h5')\n",
    "load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327\n",
      "(327,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888,\n",
       "  0.46743888],\n",
       " [3.3555405,\n",
       "  3.3555405,\n",
       "  3.3555408,\n",
       "  3.3555405,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555405,\n",
       "  3.3555405,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408,\n",
       "  3.3555408],\n",
       " [3.3927639,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927639,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636,\n",
       "  3.3927636]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y =read_csv(\"height3.csv\")\n",
    "predict_sequences_multiple(model,X_test,10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46743888],\n",
       "       [ 0.62440395],\n",
       "       [ 0.81310654],\n",
       "       [ 1.01732481],\n",
       "       [ 1.22436106],\n",
       "       [ 1.42840719],\n",
       "       [ 1.62358284],\n",
       "       [ 1.80697906],\n",
       "       [ 1.97590792],\n",
       "       [ 2.13151193],\n",
       "       [ 2.27607846],\n",
       "       [ 2.40887809],\n",
       "       [ 2.52806902],\n",
       "       [ 2.635432  ],\n",
       "       [ 2.72998214],\n",
       "       [ 2.81356788],\n",
       "       [ 2.8874476 ],\n",
       "       [ 2.95150638],\n",
       "       [ 3.00554943],\n",
       "       [ 3.05235553],\n",
       "       [ 3.09230685],\n",
       "       [ 3.12629843],\n",
       "       [ 3.15436435],\n",
       "       [ 3.17752171],\n",
       "       [ 3.19710493],\n",
       "       [ 3.21406937],\n",
       "       [ 3.22934103],\n",
       "       [ 3.24228883],\n",
       "       [ 3.25435138],\n",
       "       [ 3.26617908],\n",
       "       [ 3.27616239],\n",
       "       [ 3.28588104],\n",
       "       [ 3.29432154],\n",
       "       [ 3.30263448],\n",
       "       [ 3.31125689],\n",
       "       [ 3.31904483],\n",
       "       [ 3.32637858],\n",
       "       [ 3.33333755],\n",
       "       [ 3.33992672],\n",
       "       [ 3.34571838],\n",
       "       [ 3.3509481 ],\n",
       "       [ 3.35562253],\n",
       "       [ 3.36020732],\n",
       "       [ 3.36409593],\n",
       "       [ 3.36669636],\n",
       "       [ 3.36889076],\n",
       "       [ 3.37089133],\n",
       "       [ 3.37209511],\n",
       "       [ 3.37268734],\n",
       "       [ 3.37261176],\n",
       "       [ 3.37198091],\n",
       "       [ 3.37153554],\n",
       "       [ 3.3709712 ],\n",
       "       [ 3.3703649 ],\n",
       "       [ 3.36905956],\n",
       "       [ 3.36813545],\n",
       "       [ 3.36722898],\n",
       "       [ 3.36707902],\n",
       "       [ 3.36736417],\n",
       "       [ 3.36741304],\n",
       "       [ 3.3682878 ],\n",
       "       [ 3.36888099],\n",
       "       [ 3.36952806],\n",
       "       [ 3.37074447],\n",
       "       [ 3.37109852],\n",
       "       [ 3.3717041 ],\n",
       "       [ 3.37223363],\n",
       "       [ 3.37269044],\n",
       "       [ 3.37237716],\n",
       "       [ 3.37094235],\n",
       "       [ 3.37011981],\n",
       "       [ 3.36847711],\n",
       "       [ 3.366431  ],\n",
       "       [ 3.36401033],\n",
       "       [ 3.36123538],\n",
       "       [ 3.35956216],\n",
       "       [ 3.35763216],\n",
       "       [ 3.35588002],\n",
       "       [ 3.35431862],\n",
       "       [ 3.35293508],\n",
       "       [ 3.35171294],\n",
       "       [ 3.35207438],\n",
       "       [ 3.35260677],\n",
       "       [ 3.35369349],\n",
       "       [ 3.35458302],\n",
       "       [ 3.3562808 ],\n",
       "       [ 3.35692954],\n",
       "       [ 3.3586216 ],\n",
       "       [ 3.35915971],\n",
       "       [ 3.3606801 ],\n",
       "       [ 3.36173701],\n",
       "       [ 3.362005  ],\n",
       "       [ 3.36182499],\n",
       "       [ 3.36115766],\n",
       "       [ 3.36070657],\n",
       "       [ 3.3601501 ],\n",
       "       [ 3.35955429],\n",
       "       [ 3.35825324],\n",
       "       [ 3.35732579],\n",
       "       [ 3.35641217],\n",
       "       [ 3.35554004],\n",
       "       [ 3.35473275],\n",
       "       [ 3.3539989 ],\n",
       "       [ 3.35262394],\n",
       "       [ 3.3523767 ],\n",
       "       [ 3.35254431],\n",
       "       [ 3.35461307],\n",
       "       [ 3.35648036],\n",
       "       [ 3.35962319],\n",
       "       [ 3.3625834 ],\n",
       "       [ 3.36652756],\n",
       "       [ 3.36975908],\n",
       "       [ 3.37277317],\n",
       "       [ 3.37546682],\n",
       "       [ 3.37776899],\n",
       "       [ 3.37978649],\n",
       "       [ 3.38183999],\n",
       "       [ 3.38294339],\n",
       "       [ 3.38286662],\n",
       "       [ 3.38282347],\n",
       "       [ 3.38223982],\n",
       "       [ 3.38177943],\n",
       "       [ 3.38052011],\n",
       "       [ 3.37958288],\n",
       "       [ 3.37651896],\n",
       "       [ 3.37451816],\n",
       "       [ 3.3717742 ],\n",
       "       [ 3.37013197],\n",
       "       [ 3.37037539],\n",
       "       [ 3.37194419],\n",
       "       [ 3.37433767],\n",
       "       [ 3.37615275],\n",
       "       [ 3.3781743 ],\n",
       "       [ 3.38016176],\n",
       "       [ 3.38198519],\n",
       "       [ 3.38355303],\n",
       "       [ 3.38486314],\n",
       "       [ 3.38595986],\n",
       "       [ 3.38683987],\n",
       "       [ 3.38765788],\n",
       "       [ 3.38835979],\n",
       "       [ 3.38925123],\n",
       "       [ 3.38979006],\n",
       "       [ 3.38997769],\n",
       "       [ 3.38948941],\n",
       "       [ 3.38893485],\n",
       "       [ 3.38471413],\n",
       "       [ 3.38227844],\n",
       "       [ 3.37823224],\n",
       "       [ 3.37483811],\n",
       "       [ 3.37291074],\n",
       "       [ 3.37118793],\n",
       "       [ 3.37260461],\n",
       "       [ 3.37475705],\n",
       "       [ 3.37628341],\n",
       "       [ 3.37811017],\n",
       "       [ 3.37975907],\n",
       "       [ 3.38143229],\n",
       "       [ 3.3831718 ],\n",
       "       [ 3.38463569],\n",
       "       [ 3.38591123],\n",
       "       [ 3.38716865],\n",
       "       [ 3.38827515],\n",
       "       [ 3.38926435],\n",
       "       [ 3.3901515 ],\n",
       "       [ 3.38993239],\n",
       "       [ 3.38970518],\n",
       "       [ 3.38911557],\n",
       "       [ 3.38864732],\n",
       "       [ 3.38898873],\n",
       "       [ 3.38933277],\n",
       "       [ 3.38997054],\n",
       "       [ 3.39075351],\n",
       "       [ 3.39137506],\n",
       "       [ 3.39203954],\n",
       "       [ 3.39258528],\n",
       "       [ 3.3929677 ],\n",
       "       [ 3.39327312],\n",
       "       [ 3.39350605],\n",
       "       [ 3.39365935],\n",
       "       [ 3.39371228],\n",
       "       [ 3.39369798],\n",
       "       [ 3.39366937],\n",
       "       [ 3.39366007],\n",
       "       [ 3.39362168],\n",
       "       [ 3.39362526],\n",
       "       [ 3.3936646 ],\n",
       "       [ 3.39369941],\n",
       "       [ 3.39374781],\n",
       "       [ 3.39376259],\n",
       "       [ 3.39383578],\n",
       "       [ 3.39384747],\n",
       "       [ 3.39390922],\n",
       "       [ 3.3939538 ],\n",
       "       [ 3.3939507 ],\n",
       "       [ 3.39400458],\n",
       "       [ 3.39390969],\n",
       "       [ 3.39380479],\n",
       "       [ 3.39356685],\n",
       "       [ 3.39320636],\n",
       "       [ 3.39276338],\n",
       "       [ 3.39235997],\n",
       "       [ 3.39210963],\n",
       "       [ 3.39185929],\n",
       "       [ 3.39168572],\n",
       "       [ 3.39165068],\n",
       "       [ 3.39163995],\n",
       "       [ 3.39171767],\n",
       "       [ 3.39190269],\n",
       "       [ 3.39225221],\n",
       "       [ 3.39252257],\n",
       "       [ 3.39291453],\n",
       "       [ 3.3932941 ],\n",
       "       [ 3.39358425],\n",
       "       [ 3.39389086],\n",
       "       [ 3.39425063],\n",
       "       [ 3.39446092],\n",
       "       [ 3.39467239],\n",
       "       [ 3.39481878],\n",
       "       [ 3.3947773 ],\n",
       "       [ 3.39462781],\n",
       "       [ 3.39451814],\n",
       "       [ 3.39420986],\n",
       "       [ 3.3937242 ],\n",
       "       [ 3.39331698],\n",
       "       [ 3.39263463],\n",
       "       [ 3.39214635],\n",
       "       [ 3.39195251],\n",
       "       [ 3.39182425],\n",
       "       [ 3.39177799],\n",
       "       [ 3.39190412],\n",
       "       [ 3.39216256],\n",
       "       [ 3.39244151],\n",
       "       [ 3.39279389],\n",
       "       [ 3.39318728],\n",
       "       [ 3.39364433],\n",
       "       [ 3.3937881 ],\n",
       "       [ 3.39428878],\n",
       "       [ 3.39459705],\n",
       "       [ 3.3949461 ],\n",
       "       [ 3.3952086 ],\n",
       "       [ 3.39516211],\n",
       "       [ 3.39487004],\n",
       "       [ 3.39432549],\n",
       "       [ 3.3934567 ],\n",
       "       [ 3.39254832],\n",
       "       [ 3.39160395],\n",
       "       [ 3.3905127 ],\n",
       "       [ 3.38953018],\n",
       "       [ 3.38875103],\n",
       "       [ 3.38816285],\n",
       "       [ 3.38798165],\n",
       "       [ 3.38806081],\n",
       "       [ 3.3884685 ],\n",
       "       [ 3.38908958],\n",
       "       [ 3.38862395],\n",
       "       [ 3.3874824 ],\n",
       "       [ 3.3856833 ],\n",
       "       [ 3.38368964],\n",
       "       [ 3.38054156],\n",
       "       [ 3.37875676],\n",
       "       [ 3.37733674],\n",
       "       [ 3.37770295],\n",
       "       [ 3.37774181],\n",
       "       [ 3.37959647],\n",
       "       [ 3.38108611],\n",
       "       [ 3.38247466],\n",
       "       [ 3.38388038],\n",
       "       [ 3.38518786],\n",
       "       [ 3.38635755],\n",
       "       [ 3.38728166],\n",
       "       [ 3.388129  ],\n",
       "       [ 3.3888762 ],\n",
       "       [ 3.38962984],\n",
       "       [ 3.3904314 ],\n",
       "       [ 3.39089084],\n",
       "       [ 3.39101529],\n",
       "       [ 3.39130998],\n",
       "       [ 3.39154029],\n",
       "       [ 3.39129472],\n",
       "       [ 3.39122891],\n",
       "       [ 3.39068341],\n",
       "       [ 3.38989425],\n",
       "       [ 3.38885307],\n",
       "       [ 3.38800311],\n",
       "       [ 3.38714671],\n",
       "       [ 3.38632894],\n",
       "       [ 3.38557553],\n",
       "       [ 3.38489604],\n",
       "       [ 3.38429093],\n",
       "       [ 3.384197  ],\n",
       "       [ 3.3835125 ],\n",
       "       [ 3.38312364],\n",
       "       [ 3.38221049],\n",
       "       [ 3.38159442],\n",
       "       [ 3.38098121],\n",
       "       [ 3.37968731],\n",
       "       [ 3.37878108],\n",
       "       [ 3.37789059],\n",
       "       [ 3.37774634],\n",
       "       [ 3.37661099],\n",
       "       [ 3.37592268],\n",
       "       [ 3.3752799 ],\n",
       "       [ 3.37467933],\n",
       "       [ 3.37412524],\n",
       "       [ 3.37361813],\n",
       "       [ 3.37386179],\n",
       "       [ 3.37379766],\n",
       "       [ 3.37379622],\n",
       "       [ 3.37438846],\n",
       "       [ 3.3751502 ],\n",
       "       [ 3.3765893 ],\n",
       "       [ 3.37871528],\n",
       "       [ 3.38021135],\n",
       "       [ 3.38170838],\n",
       "       [ 3.38302445],\n",
       "       [ 3.38414621],\n",
       "       [ 3.38507533],\n",
       "       [ 3.38574338],\n",
       "       [ 3.38620591],\n",
       "       [ 3.38640618],\n",
       "       [ 3.38635087],\n",
       "       [ 3.3861146 ],\n",
       "       [ 3.3852756 ],\n",
       "       [ 3.38389516],\n",
       "       [ 3.38248897],\n",
       "       [ 3.38092327]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict_sequences_multiple(model, X_test,10,50)\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.93  6.9   6.86  6.83  6.8   6.77  6.74  6.71  6.68  6.65  6.62  6.62\n",
      "  6.62  6.62  6.51  6.49  6.46  6.43  6.41  6.38  6.36  6.33  6.31  6.28\n",
      "  6.27  6.26  6.24  6.23  6.21  6.2   6.19  6.17  6.17  6.14  6.14  6.13\n",
      "  6.12  6.12  6.11  6.11  6.11  6.11  6.11  6.11  6.11  6.11  6.11  6.11\n",
      "  6.1   6.1   6.1   6.09  6.09  6.08  6.07  6.06  6.05  6.04  6.03  6.02\n",
      "  6.01  6.    5.98  5.97  5.96  5.94  5.94  5.93  5.92  5.91  5.9   5.89\n",
      "  5.88  5.87  5.87  5.87  5.87  5.88  5.88  5.88  5.89  5.9   5.9   5.91\n",
      "  5.92  5.93  5.94  5.94  5.94  5.94  5.95  6.    6.02  6.03  6.04  6.04\n",
      "  6.04  6.05  6.05  6.05  6.05  6.05  6.06  6.06  6.05  6.05  6.05  6.05\n",
      "  6.04  6.03  6.02  6.02  6.01  5.99  5.99  5.97  5.96  5.95  5.94  5.92\n",
      "  5.9   5.89  5.88  5.86  5.84  5.83  5.8   5.8   5.77  5.76  5.74  5.72\n",
      "  5.69  5.67  5.65  5.64  5.63  5.61  5.59  5.58  5.56  5.55  5.53  5.52\n",
      "  5.5   5.49  5.47  5.46  5.44  5.42  5.41  5.39  5.37  5.36  5.33  5.31\n",
      "  5.3   5.27  5.26  5.25  5.24  5.22  5.21  5.2   5.18  5.16  5.15  5.14\n",
      "  5.14  5.13  5.13  5.13  5.14  5.16  5.17  5.18  5.2   5.21  5.24  5.27\n",
      "  5.3   5.35  5.41  5.48  5.56  5.74  5.83  5.93  6.01  6.11  6.2   6.29\n",
      "  6.45  6.52  6.58  6.65  6.7   6.76  6.81  6.84  6.92  6.94  6.96  6.97\n",
      "  6.98  6.98  6.97  6.96  6.95  6.93  6.92  6.89  6.87  6.85  6.82  6.79\n",
      "  6.73  6.7   6.67  6.63  6.6   6.57  6.54  6.51  6.49  6.46  6.44  6.41\n",
      "  6.39  6.36  6.34  6.32  6.29  6.27  6.25  6.23  6.21  6.19  6.18  6.15\n",
      "  6.14  6.11  6.09  6.07  6.06  6.03  6.01  5.99  5.97  5.94  5.89  5.64\n",
      "  5.5   5.35  5.2   5.06  4.93  4.8   4.7   4.55  4.74  4.58  4.71  4.73\n",
      "  4.58  4.65  4.72  4.74  4.75  4.75  4.74  4.73  4.68  4.6   4.5   4.39\n",
      "  4.31  4.22  4.14  4.08  4.05  4.27  4.18  4.12  4.05  4.03  4.1   4.4\n",
      "  4.9   5.1   5.2   5.3   5.4   5.5   5.6   5.7   5.8   5.85  6.    6.\n",
      "  5.99  5.99  5.99  5.99  6.    6.01  6.07  6.12  6.15  6.17  6.21  6.23\n",
      "  6.27  6.29  6.31  6.33  6.34  6.35  6.37  6.37  6.38  6.4   6.4   6.4\n",
      "  6.4   6.4   6.38]\n"
     ]
    }
   ],
   "source": [
    "# The actual values\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from tensorflow.contrib.session_bundle import exporter\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "export_path = saved # where to save the exported graph\n",
    "export_version = 1 # version number (integer)\n",
    "\n",
    "saver = tf.train.Saver(sharded=True)\n",
    "model_exporter = exporter.Exporter(saver)\n",
    "signature = exporter.classification_signature(input_tensor=model.input,\n",
    "                                              scores_tensor=model.output)\n",
    "model_exporter.init(sess.graph.as_graph_def(),\n",
    "                    default_graph_signature=signature)\n",
    "model_exporter.export(export_path, tf.constant(export_version), sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
